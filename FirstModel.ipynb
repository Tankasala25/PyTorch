{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPwMi9NnJNn3QlhkUGOWpeR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tankasala25/PyTorch/blob/main/FirstModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Simple Definition of `torch.nn`\n",
        "\n",
        "`torch.nn` is the PyTorch module that provides the basic building blocks for creating neural networks, including layers, activation functions, and loss functions.\n",
        "\n",
        "## 1. Optimizer\n",
        "The optimizer **updates the model's weights** using the gradients.  \n",
        "Example: SGD, Adam.\n",
        "\n",
        "---\n",
        "\n",
        "## 2. backward() Function\n",
        "The `backward()` function **calculates the gradients** of the loss with respect to each weight.  \n",
        "These gradients are then passed to the optimizer.\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Gradient Descent\n",
        "Gradient Descent is the overall **process** where:\n",
        "- `backward()` computes gradients  \n",
        "- the optimizer updates weights  \n",
        "- and the model gradually reduces the loss  \n",
        "\n",
        "In simple words:  \n",
        "**Gradient Descent = calculate gradients + update weights to reduce loss.**\n"
      ],
      "metadata": {
        "id": "-FM6TeGKPaDZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PgaJj8CxS49C",
        "outputId": "3ced914e-9844-4ebb-d983-5d447d2278b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "prediction before training: f(5)= -2.347\n",
            "Epoch 1: weight=0.051, loss=90.28034973\n",
            "Epoch 11: weight=2.419, loss=3.49922514\n",
            "Epoch 21: weight=2.886, loss=0.13562892\n",
            "Epoch 31: weight=2.977, loss=0.00525692\n",
            "Epoch 41: weight=2.996, loss=0.00020374\n",
            "Epoch 51: weight=2.999, loss=0.00000790\n",
            "Epoch 61: weight=3.000, loss=0.00000031\n",
            "Epoch 71: weight=3.000, loss=0.00000001\n",
            "Epoch 81: weight=3.000, loss=0.00000000\n",
            "Epoch 91: weight=3.000, loss=0.00000000\n",
            "prediction After training: f(5)= 15.000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "x=torch.tensor([1,2,3,4],dtype=torch.float32)\n",
        "y=torch.tensor([3,6,9,12],dtype=torch.float32)\n",
        "\n",
        "class Linearmodel(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.weight=nn.Parameter(torch.randn(1,requires_grad=True,dtype=torch.float32))\n",
        "\n",
        "  def forward(self,x):\n",
        "    return self.weight*x\n",
        "\n",
        "model=Linearmodel()\n",
        "\n",
        "loss=nn.MSELoss()\n",
        "optimizer=torch.optim.SGD(model.parameters(),lr=0.01)\n",
        "learning_rate=0.01\n",
        "iters=100\n",
        "\n",
        "print(f\"prediction before training: f(5)= {model(torch.tensor(5.0)).item():.3f}\")\n",
        "\n",
        "for epoch in range(iters):\n",
        "\n",
        "  #first we have to do forward function\n",
        "  y_pred=model(x)\n",
        "\n",
        "  #then we have to do loss function\n",
        "  l=loss(y,y_pred)\n",
        "\n",
        "  #we have to find gradient\n",
        "  l.backward()\n",
        "\n",
        "  #we have to update weights\n",
        "  optimizer.step()\n",
        "\n",
        "  #we have to zero gradient\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if epoch%10==0:\n",
        "    print(f\"Epoch {epoch+1}: weight={model.weight.item():.3f}, loss={l.item():.8f}\")\n",
        "\n",
        "print(f\"prediction After training: f(5)= {model(torch.tensor(5.0)).item():.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "---\n",
        "\n",
        "# üìò **Cell 4 ‚Äî Difference between saving entire model and model state dictionary**\n",
        "\n",
        "```markdown\n",
        "## ‚úÖ Side-by-Side Comparison\n",
        "\n",
        "| Feature | Saving Entire Model | Saving `state_dict` |\n",
        "|--------|---------------------|----------------------|\n",
        "| Saves architecture | ‚úî Yes | ‚ùå No |\n",
        "| Saves weights | ‚úî Yes | ‚úî Yes |\n",
        "| Loading requires class definition | ‚ùå No | ‚úî Yes |\n",
        "| Version stability | ‚ùå Low | ‚úî High |\n",
        "| Production use (Triton, ONNX) | ‚ùå Not recommended | ‚úî Recommended |\n",
        "| File size | Larger | Smaller |\n",
        "| PyTorch recommended | ‚ùå No | ‚úî Yes |\n"
      ],
      "metadata": {
        "id": "PO92nFeLGll8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.state_dict()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRLoYKFJGt6B",
        "outputId": "6f96acd1-9bf0-4387-c659-75e6e7fc3416"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([3.0000]))])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "#Creating a model Directory path\n",
        "\n",
        "MODEL_Path=Path(\"Models\")\n",
        "MODEL_Path.mkdir(parents=True,exist_ok=True)\n",
        "\n",
        "#Creating a model save path\n",
        "\n",
        "Model_name= \"Pytorch_FirstModel.pth\"\n",
        "Model_save_Path=MODEL_Path/Model_name\n",
        "\n",
        "#Saving a Model\n",
        "print(f\"Saving model to path :{Model_save_Path}\")\n",
        "torch.save(obj=model.state_dict(),f=Model_save_Path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wg7JHtZkG89O",
        "outputId": "a70cfd91-7b4b-4011-e62d-04bf95f54687"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving model to path :Models/Pytorch_FirstModel.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -l Models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJB0HUhdJROu",
        "outputId": "c45efa83-127e-4307-ef33-fd2611aa4274"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 4\n",
            "-rw-r--r-- 1 root root 1718 Nov 18 18:05 Pytorch_FirstModel.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loading Models in PyTorch ‚Äî All Key Points\n",
        "\n",
        "## 1. Loading the Entire Model\n",
        "- Use this when the model was saved using: `torch.save(model, \"model.pth\")`\n",
        "- Load it directly with: `model = torch.load(\"model.pth\")`\n",
        "- Automatically restores architecture + weights\n",
        "- Does NOT require the model class definition\n",
        "- Very easy but NOT recommended for production use\n",
        "\n",
        "---\n",
        "\n",
        "## 2. Loading a Model Using state_dict (Recommended)\n",
        "- Use when saved using: `torch.save(model.state_dict(), \"model_state.pth\")`\n",
        "- Requires recreating the exact same model architecture\n",
        "- Steps:\n",
        "  1. Define the model class\n",
        "  2. Create an instance of the model\n",
        "  3. Load weights using: `model.load_state_dict(torch.load(\"model_state.pth\"))`\n",
        "- Most stable and production-ready\n",
        "- Works best with ONNX, TorchScript, TensorRT, Triton\n",
        "\n",
        "---\n",
        "\n",
        "## 3. Loading a Model on CPU or GPU\n",
        "- Load on CPU: use `map_location=\"cpu\"`\n",
        "- Load on GPU: use `map_location=\"cuda\"` or a device variable\n",
        "- After loading, move the model to device using: `model.to(device)`\n",
        "- Needed when model was trained on one device and loaded on another\n",
        "\n",
        "---\n",
        "\n",
        "## 4. Loading Checkpoints (Model + Optimizer)\n",
        "- Used when resuming training\n",
        "- Checkpoint usually contains:\n",
        "  - epoch number\n",
        "  - model_state_dict\n",
        "  - optimizer_state_dict\n",
        "  - loss value\n",
        "- Requires:\n",
        "  1. Recreating the model architecture\n",
        "  2. Recreating the optimizer\n",
        "  3. Loading both states from the checkpoint dictionary\n",
        "- Useful to continue training exactly where it stopped\n",
        "\n",
        "---\n",
        "\n",
        "## 5. Summary\n",
        "- Entire Model:\n",
        "  - Easy to load\n",
        "  - No class needed\n",
        "  - Not production-safe\n",
        "\n",
        "- state_dict (Recommended):\n",
        "  - Class must be recreated\n",
        "  - Loads only weights\n",
        "  - Industry standard, best for deployment\n",
        "\n",
        "- Checkpoint:\n",
        "  - Loads model + optimizer\n",
        "  - Best for resuming training\n"
      ],
      "metadata": {
        "id": "tZJUQGU_Lf4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#To Load a saved model state we have to create a new instance for Model class\n",
        "Model_loaded_state=Linearmodel()\n",
        "\n",
        "#Load the model with saved model state dictionary\n",
        "Model_loaded_state.load_state_dict(torch.load(f=Model_save_Path))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdRobfYaJUSJ",
        "outputId": "40dafffd-c31c-431d-9c5c-2e6366c4da98"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_loaded_state.state_dict()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sv9z46dQMavf",
        "outputId": "6058f9fb-4da1-41ad-cd52-59bba6425248"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('weight', tensor([3.0000]))])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Model_loaded_state.eval()\n",
        "with torch.inference_mode():\n",
        "  y_pred=Model_loaded_state(torch.tensor([5,6,7,8],dtype=torch.float32))\n",
        "\n",
        "y_pred"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46TysRStM928",
        "outputId": "52754e17-b450-4388-8ccd-a32a6c775a8b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([15.0000, 18.0000, 21.0000, 24.0000])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T8l7AmzmNbeC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}